{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23, Jan, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 특성 스케일 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "## 특성을 만듭니다.\n",
    "feature = np.array([[-500.5],\n",
    "                   [-100.1],\n",
    "                   [0],\n",
    "                   [100.1],\n",
    "                   [900.9]])\n",
    "\n",
    "## 스케일러 객체를 만듭니다.\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "## 특성의 스케일을 변환합니다.\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "## 특성을 출력합니다.\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일 조정은 머신러닝에서 흔한 전처리 작업입니다. 이 책에서 설명하는 대부분의 알고리즘은 모든 특성이 동일한 스케일을 가지고 있다고 가정합니다. 일반적으로 0 ~ 1이나 -1~1 사이입니다. 스케일 조정 기법은 여러 가지인데, 가장 간단한 방법은 최소-최대 스케일링(min-max scaling)입니다. 최소-최대 스케일링은 특성의 최솟값과 최댓값을 사용하여 일정 범위 안으로 값을 조정합니다. 구체적으로 최소-최대 스케일링은 다음과 같이 계산됩니다.\n",
    "\n",
    "$$x_{i}^{'} = \\frac{x_i-min(x)}{max(x)-min(x)}$$\n",
    "\n",
    "$x$는 특성 벡터이고 $x_i$는 특성 $x$의 개별 원소입니다. $x_{i}^{'}$ 는 스케일이 바뀐 원소입니다.이 예에서는 출력 배열의 스케일이\n",
    "0에서 1 사이로 성공적으로 바뀌었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런의 MinMaxScaler는 특성 스케일을 위해 두 가지 방법을 제공합니다. 첫 번째로 fit 메서드를 사용해 특성의 최솟값과 최댓값을 계산한 다음 transform 메서드로 특성의 스케일을 조정합니다. 두 번째로 fit_transform 메서드로 두 연산을 한번에 처리합니다. 이 둘 사이에 계산 상의 차이는 없습니다. 동일한 변환을 다른 데이터 세트에 적용하려면 fit 메서드와 transform 메서드를 따로 호출해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.8],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트와 테스트 세트의 스케일을 따로 조정하면 안 됩니다 예를 들면 훈련 세트의 스케일을 조정하고자 구한 최솟값과 최댓값을 사용하여\n",
    "# 테스트 세트를 변환해야 합니다. 간단한 예를 통해 이유를 알아보죠,\n",
    "\n",
    "# 해결에 있는 샘플 중 처음 세 개를 훈련 세트, 나머지 두 개를 테스트 세트라고 가정해보겠습니다. \n",
    "# 먼저 두 세트를 독립적으로 각각 변환합니다.\n",
    "\n",
    "## 훈련 세트를 변환합니다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 테스트 세트를 변환합니다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.8],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트와 테스트 세트를 각각 변환하면 서로 다른 비율로 데이터를 변환합니다. 훈련 세트에 있는 0과 테스트 세트에 있는 900.1가 모두\n",
    "# 1로 바뀌었습니다. 데이터가 다른 스케일로 변환되면 훈련 세트에서 학습한 모델을 테스트 세트에서 사용할 수 없습니다.\n",
    "\n",
    "# 이번에는 훈련 세트에서 학습한 변환기로 테스트를 학습해보죠.\n",
    "\n",
    "## 훈련 세트로 변환기를 학습합니다.\n",
    "scaler = preprocessing.MinMaxScaler().fit(feature[:3])\n",
    "scaler.transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2],\n",
       "       [2.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 훈련 세트에서 학습한 변환기로 테스트 세트를 변환합니다.\n",
    "scaler.transform(feature[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 특성을 표준화하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "## 특성을 만듭니다.\n",
    "x = np.array([[-1000.1],\n",
    "             [-200.2],\n",
    "             [500.5],\n",
    "             [600.6],\n",
    "             [9000.9]])\n",
    "\n",
    "## 변환기 객체를 만듭니다.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "## 특성을 변환합니다.\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "## 특성을 출력합니다.\n",
    "standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레시피 4.1에서 설명한 최소-최대 스케일링과 함께 특성을 표준 정규분포로 근사하는 스케일링 방식이 자주 쓰입니다. \n",
    "이 방식은 표준화를 사용하여 데이터의 평균 $\\bar{x}$가 0이고 표준편차 $\\sigma$가 1이 되도록 변환합니다.\n",
    "구체적으로 각 특성은 다음과 같이 변환됩니다.\n",
    "$$ x_{i}^{'} = \\frac{x_{i} - \\bar{x}}{\\sigma} $$\n",
    "\n",
    "$x_{i}^{'}$ 는 $x_{i}$의 표준화된 형태입니다. 변환된 특성은 원본 값이 특성 평균에서 몇 표준편차만큼 떨어져 있는지로 표현합니다.\n",
    "(통계학에서는 z-점수라고도 부릅니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: 0\n",
      "표준편차: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 표준화는 머신러닝의 일반적인 전처리 단계에서 사용할 수 있는 믿을 만한 스케일링 방법입니다. \n",
    "# 제 경험으로 비추어보았을 때 최소-최대 스케일링보다 많이 쓰입니다. 하지만 학습 알고리즘에 의존적입니다. \n",
    "# 예를 들어 주성분 분석(principal component analysis)은 표준화가 잘 맞지만 \n",
    "# 신경망(neural network)에는 최소-최대 스케일링을 종종 권장합니다. \n",
    "# 일반적으로 다른 방법을 사용할 특별한 이유가 없다면 기본으로 표준화를 권장합니다.\n",
    "\n",
    "# 해결의 출력 결과에서 평균과 표준편차를 구해 표준화의 효과를 확인해보겠습니다.\n",
    "\n",
    "print(\"평균:\", round(standardized.mean()))\n",
    "print(\"표준편차:\", standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터에 이상치가 많다면 특성의 평균과 표준편차에 영향을 미치기 때문에 표준화에 부정적인 효과를 끼칩니다. 이런 경우에는 중간값과 사분위 범위를 사용하여 특성의 스케일을 조정하는 것이 좋습니다. 사이킷런의 RobustScaler가 이런 방법을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 변환기 객체를 만듭니다.\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "## 특성을 변환합니다.\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RobustScaler는 데이터에서 중간값을 빼고 IQR로 나눕니다.\n",
    "\n",
    "interquatile_range = x[3] -x[1]\n",
    "(x- np.median(x)) / interquatile_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dain\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2367: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QuantileTransformer는 훈련 데이터를 1,000개 분위로 나누어 0~1 사이에 고르게 분포시킴으로써 이상치로 인한 영향을 줄입니다.\n",
    "# 예를 들어 해결에 나온 특성 x는 다섯 개의 샘플을 가지고 있으므로 0%, 25%, 50%, 75%, 100%의 위치에 할당합니다.\n",
    "\n",
    "preprocessing.QuantileTransformer().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "features = np.array([[0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.4],\n",
    "                    [10.9, 3.3]])\n",
    "\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 스케일링 방법이(예를 들면 최소-최대 스케일링과 표준화와 같이) 특성별로 적용되지만 샘플별로 스케일을 바꿀 수도 있습니다.Normalizer는 단위 노름(길이의 합이 1입니다)이 되도록 개별 샘플의 값을 변환합니다. 이런 종류의 스케일링은 (예를 들어 각 단어나 n개의)단어 그룹이 특성인 텍스트 분류와 같이) 유사한 특성이 많을 때 종종 사용합니다.\n",
    "\n",
    "Normalizer는 세 가지 노름 옵션을 제공합니다. 그 중 L2 노름이라고도 부르는 유클리드 노름이 기본값입니다.\n",
    "$$ \\left\\|x \\right\\|_2 = \\sqrt{x_{1}^{2}+x_{2}^{2}+\\cdots +x_{n}^{2}} $$\n",
    "\n",
    "$x$는 개별 샘플이고 $x_n$은 샘플의 $n$번째 특성값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_l2_norm = Normalizer(norm=\"l2\").transform(features)\n",
    "\n",
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맨해튼 노름(L2)을 지정할 수도 있습니다.\n",
    "\n",
    "$$ \\left\\|x \\right\\|_1 = \\sum_{i=1}^{n}\\left|x_i\\right| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플값의 합: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 직관적으로 생각했을 때 L2 노름은 뉴욕의 두 지점 사이를 잇는 직선 거리로 볼 수있습니다. \n",
    "# L1 노름은 사람이 도로를 따라 걷는 것과 같습니다. 그래서 '맨해튼 노름' 또는 '택시 노름'으로 부릅니다.\n",
    "\n",
    "# norm=\"l1\"은 각 샘플 특성값의 합을 1로 만듭니다. 실제 이런 성질이 가끔 필요할 때가 있습니다.\n",
    "\n",
    "print(\"첫 번째 샘플값의 합:\",\n",
    "     features_l1_norm[0,0] + features_l1_norm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizer는 행 단위로 변환되므로 fit 메서드는 아무런 작업을 수행하지 않습니다. 이런 이유로 해결의 코드처럼 \n",
    "# 바로 transform 메서드를 사용할 수 있습니다. 'l1'과 'l2' 옵션의 변환은 각 행의 L1 노름과 L2 노름을 구해 나누는 것입니다.\n",
    "\n",
    "## L1 노름을 사용한 변환.\n",
    "## 각 행(axis=1)을 합한 결과가 2차원 배열로 유지되도록\n",
    "## keepdims를 True로 설정합니다.\n",
    "\n",
    "features / np.sum(np.abs(features), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## L2 노름을 사용한 변환\n",
    "\n",
    "features / np.sqrt(np.sum(np.square(features), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        ],\n",
       "       [0.32352941, 1.        ],\n",
       "       [0.07425743, 1.        ],\n",
       "       [0.04738372, 1.        ],\n",
       "       [1.        , 0.30275229]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizer의 norm 매개변수에 지정할 수 있는 다른 한 가지 옵션은 'max' 입니다. 이 옵션은 단순히 각 행의 최댓값으로 행의 값을 나눕니다.\n",
    "\n",
    "Normalizer(norm=\"max\").transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 다항 특성과 교차항 특성 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "features = np.array([[2, 3],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "degree 매개변수가 다항식의 최대 차수를 결정합니다. 예를 들어 degree=2는 2제곱까지 새로운 특성을 만듭니다.\n",
    "\n",
    "$$x_1, x_2, x_1^{2}, x_{2}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "degree=3은 2제곱과 3제곱까지 새로운 특성을 만듭니다.\n",
    "$$x_1, x_2, x_1^2, x_2^2, x_{1}^{3}, x_{2}^3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 PolynomialFeatures는 교차항을 포함합니다.\n",
    "$$x_1x_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interaction_only를 True로 지정하면 교차항 특성만 만들 수 있습니다.\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2,\n",
    "                                 interaction_only=True, include_bias=False)\n",
    "\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성과 타깃 사이에 비선형 관계가 있다는 가정을 추가할 때 다항 특성을 종종 만듭니다. 예를 들면 주요 질병에 걸릴 확률에 나이가 미치는 영향은 일정한 상숫값이 아니고 나이가 증가함에 따라 같이 증가한다는 의심을 할 수 있습니다. 특성 $x$에 변동 효과를 주입하기 위해서 고차항 트겅을 만들 수 있습니다($x^2$, $x^3$ 등).\n",
    "\n",
    "또한 한 특성의 효과가 다른 특성에 의존하는 경우를 자주 만나게 됩니다. 간단한 예는 커피가 달달한지 예측하는 문제입니다. 여기에는 두 개의 특성이 있습니다. 1) 커피를 저었는지 여부 2) 설탕을 넣었는지 여부입니다. 각 특성은 독립적으로는 커피의 당도를 예측하지 못하지만 이 둘의 조합은 가능합니다. 즉 커피에 설탕을 넣고 저었을 때에만 커피가 달달합니다. 타깃(달달함)에 대한 각 특성의 영향은 서로에게 종속적입니다. 개별 특성을 곱한 교차항을 특성에 추가하여 이런 관계를 인코딩할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 6., 9.],\n",
       "       [1., 2., 3., 4., 6., 9.],\n",
       "       [1., 2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include_bias 매개변수의 기본값은 True입니다. 이 설정은 변환된 특성에 상수항 1을 추가합니다.\n",
    "\n",
    "polynomial_bias = PolynomialFeatures(degree=2,\n",
    "                                     include_bias=True).fit(features)\n",
    "\n",
    "polynomial_bias.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'polynomial_bias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2eccb02b287c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get_feature_names_out 메서드는 특성 변환 식을 이름으로 반환합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpolynomial_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'polynomial_bias' is not defined"
     ]
    }
   ],
   "source": [
    "# get_feature_names_out 메서드는 특성 변환 식을 이름으로 반환합니다.\n",
    "\n",
    "polynomial_bias.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25, Jan, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 특성 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = np.array([[2, 3], \n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "# 간단한 함수를 정의합니다.\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "\n",
    "# 변환기 객체를 만듭니다.\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "# 특성 행렬을 변환합니다.\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스의 apply 메서드를 사용하여 동일한 변환을 수행할 수 있습니다.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나 이상의 특성에 사용자 정의 변환이 필요한 경우는 흔합니다. 예를 들면 특성값에 자연 로그를 취한 특성을 만들어야 할 수 있습니다. 함수를 하나 만들고 사이킷런이나 판다스의 apply를 사용하여 특성에 매핑합니다. 해결에서는 입력값에 10을 더하는 아주 간단한 add_ten 함수를 만들었습니다. 하지만 훨씬 더 복잡한 함수를 만들지 못할 이유가 없습니다. \n",
    "\n",
    "FunctionTransformer의 validate 매개변수가 True이면 입력값이 2차원 배열 지 확인하고 아닐 경우 예외를 발생시킵니다. 사이킷런 0.22 버전에서 validate의 기본값이 True에서 False로 변경됩니다. validate가 False이면 일차원 배열에도 적용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FunctionTransformer(add_ten, validate=False).transform(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 0.20 버전에 추가된 ColumnTransformer를 사용하면 특성 배열이나 데이터프레임의 열마다 다른 변환을 적용할 수 있습니다. 예를 들면 feature_1 열은 10을 더하고 feature_2 열은 100을 더한다고 가정하면 다음과 같이 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12, 103],\n",
       "       [ 12, 103],\n",
       "       [ 12, 103]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def add_hundred(x):\n",
    "    return x + 100\n",
    "\n",
    "\n",
    "# (이름, 변환기, 열 리스트)로 구성된 튜플의 리스트를 ColumnTransformer에 전달합니다.\n",
    "ct = ColumnTransformer(\n",
    "    [(\"add_ten\", FunctionTransformer(add_ten, validate=True), ['feature_1']),\n",
    "     (\"add_hundred\", FunctionTransformer(add_hundred, validate=True),['feature_2'])])\n",
    "\n",
    "ct.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 이상치 감지하기\n",
    "일반적인 방법은 데이터가 정규분포를 따른다고 가정하고 이런 가정을 기반으로 데이터를 둘러싼 타원을 그립니다. 이 타원 안의 샘플을 정상치(레이블 1)로 분류하고, 타원 밖의 샘플은 이상치(레이블-1)로 분류합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets  import make_blobs\n",
    "\n",
    "# 모의 데이터를 만듭니다.\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                         n_features = 2,\n",
    "                         centers = 1,\n",
    "                         random_state = 1)\n",
    "\n",
    "# 첫 번째 샘플을 극단적인 값으로 바꿉니다.\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "\n",
    "# 이상치 감지 객체를 만듭니다.\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "\n",
    "# 감지 객체를 훈련합니다.\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "# 이상치를 예측합니다.\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식의 주요 단점은 이상치의 비율을 정하는 contamination 매개변수를 지정해야 한다는 것입니다. 실제로는 알지 못합니다. contamination은 데이터가 얼마나 깨끗한지 추측하는 것으로 볼 수 있습니다. 데이터에 이상치가 적다면 contamination을 작게 지정할 수 있습니다. 데이터에 이상치가 많다고 생각한다면 이 값을 크게 설정해야 합니다.\n",
    "\n",
    "샘플을 전체적으로 보는 것보다 개별 특성에서 사분위범위(IQR)를 사용하여 극단적인 값을 구별할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하나의 특성을 만듭니다.\n",
    "feature = features[:,0]\n",
    "\n",
    "# 이상치의 인덱스를 반환하는 함수를 만듭니다.\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "\n",
    "# 함수를 실행합니다.\n",
    "indicies_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치를 감지하는 최선의 방법은 없습니다. 일련의 도구들은 저마다 장단점을 가집니다. 최선의 전략은 여러 가지 방법을 시도해보고 (예를 들어 EllipticEnvelope와 IQR 기반 감지) 종합적으로 결과를 살펴보는 것입니다.\n",
    "\n",
    "가능하다면 이상치로 감지한 샘플을 살펴보고 이해하려고 노력해야 합니다. 예를 들어 주택 데이터셋에 방ㅇ의 개수를 나타내는 특성이 있을 때 100개의 방을 가진 집은 이상치일까요? 아니면 실제 호텔을 잘못 분류한 것일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 이상치 다루기\n",
    "### 1. 이상치를 삭제하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_Feet\n",
       "0  534433        2.0         1500\n",
       "1  392333        3.5         2500\n",
       "2  293222        2.0         1500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]\n",
    "\n",
    "# 샘플을 필터링합니다.\n",
    "houses[houses['Bathrooms'] < 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 이상치로 표현하고 특성의 하나로 포함시키는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Sqare_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Sqare_Feet  Outlier\n",
       "0   534433        2.0        1500        0\n",
       "1   392333        3.5        2500        0\n",
       "2   293222        2.0        1500        0\n",
       "3  4322032      116.0       48000        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 불리언 조건을 기반으로 특성을 만듭니다.\n",
    "houses['Outlier'] = np.where(houses['Bathrooms'] < 20, 0, 1)\n",
    "\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 이상치의 영향이 줄어들도록 특성을 변환하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Log_Of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Log_Of_Square_Feet\n",
       "0   534433        2.0         1500            7.313220\n",
       "1   392333        3.5         2500            7.824046\n",
       "2   293222        2.0         1500            7.313220\n",
       "3  4322032      116.0        48000           10.778956"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로그 특성\n",
    "houses[\"Log_Of_Square_Feet\"] = [np.log(x) for x in houses[\"Square_Feet\"]]\n",
    "\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치 감지와 마찬가지로, 이상치를 다룰 때 언제나 적용할 수 있는 좋은 처리 방법이란 없습니다. 대신 두 가지 측면에서 처리 방법을 고려해야 합니다. 첫째, 어떤 것을 이상치로 간주할 것인지 생각해야 합니다. 고장난 센서나 잘못 인코딩된 값 때문에 데이터에 오류가 있다고 생각되면 이 값을 신뢰할 수 없으므로 이 샘플을 삭제하거나 이상치를 NaN으로 바꿀 수 있습니다. 극단적인 값을 가진 샘플이라면 이를 이상치로 표시하거나 적절한 값으로 변환합니다.\n",
    "\n",
    "둘째, 이상치를 다루는 방법이 머신러닝의 목적에 맞아야 합니다. 예를 들어 집의 특성값을 기반으로 주택 가격을 예측한다면 100개의 방을 가진 집의 가격은 일반적인 주택과 다른 방식으로 정해진다고 가정할 수 이습니다. 또한 온라인 주택 대출 웹 애플리케이션의 일부로 머신러닝 모델을 훈련한다면 잠재 고객 중에 100개의 방을 가진 집을 구입할 만한 백만장자는 없을 것입니다.\n",
    "\n",
    "그럼 이상치가 있을 때 어떻게 해야 할까요? 왜 그 데이터가 이상치인지 생각해보세요. 마음 속에 있는 최종 목적을 생각하세요. 무엇보다도 이상치라고 결정하지 않는 것 자체가 암묵적인 결정이라는 것을 기억하세요.\n",
    "\n",
    "한 가지 추가로 언급할 것이 있습니다. 이상치가 평균과 분산에 영향을 끼치기 때문에 이상치가 있다면 표준화가 적절하지 않습니다. RobustScaler와 같이 이상치에 민감하지 않은 스케일링 방법을 사용하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 특성 이산화하기\n",
    "### 1. 임계값에 따라 특성을 둘로 나누는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "age = np.array([[6],\n",
    "                [12],\n",
    "                [20],\n",
    "                [36],\n",
    "                [65]])\n",
    "\n",
    "binarizer = Binarizer(threshold=18)\n",
    "\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 수치 특성을 여러 임곗값에 따라 나누는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(age, bins=[20, 30, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bins 매개변수의 입력값은 각 구간의 왼쪽 경곗값입니다. 예를 들어 20까지 구간에는 값이 20인 원소가 포함되지 않고 20보다 작은 두 개만 포함됩니다. right 매개변수를 True로 설정하면 이 동작을 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(age, bins=[20,30,64], right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이산화는 수치 특성을 범주형처럼 다루어야 할 때 유용한 전략입니다. 예를 들어 19세와 20세의 소비 습관은 차이가 매우 작지만 20세와 21세 사이는 차이가 클 수 있습니다. 이런 경우엔 술을 마실 수 있는 사람과 그렇지 않은 사람으로 구분하는 것이 좋습니다. 경우에 따라서는 세 개나 그 이상의 구간으로 나누는 것이 좋을 수도 있습니다.\n",
    "\n",
    "이번 해결에서는 두 가지 이산화 방법을 살펴보았습니다. 두 개의 구간으로 나누는 사이킷런의 Binarizer와 세 개 이상의 구간으로 넘파이의 digitize입니다. digitize에 하나의 임곗값만 지정하면 Binarizer처럼 특성을 두 개의 구간으로 나눌 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(age, bins=[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런 0.20 버전에서는 연속적인 특성값을 여러 구간으로 나누어주는 KBinsDiscretizer 클래스가 추가되었습니다.\n",
    "# 이 클래스는 나눌 구간 개수를 지정합니다.\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "kb = KBinsDiscretizer(4, encode='ordinal', strategy='quantile')\n",
    "kb.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode 매개변수의 기본값은 'onehot'으로 원-핫 인코딩된 희소 행렬을 반환합니다. 'onehot-dense'는 원-핫 이코딩된 밀집 배열을 반환합니다. 연속된 값을 이산화하여 원-핫 인코딩으로 만들면 범주형 특성으로 다루기 편리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb = KBinsDiscretizer(4, encode='onehot-dense', strategy='quantile')\n",
    "kb.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strategy 매개변수의 기본값은 'quantile'로 각 구간에 포함된 샘플 개수가 비슷하도록 만듭니다. 'uniform'은 구간의 폭이 동일하도록 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb = KBinsDiscretizer(4, encode='onehot-dense', strategy='uniform')\n",
    "kb.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구간은 bin_edges_ 속성에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 6.  , 20.75, 35.5 , 50.25, 65.  ])], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.bin_edges_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작과 끝 경계는 처음과 마지막 구간에 포함됩니다. 나머지 경곗값은 왼쪽 경계를 나타냅니다. 즉 첫 번째 구간은 [6.0, 20.75]이고 두 번째 구간은 [20.75, 35.5]가 되는 식입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
