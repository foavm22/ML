{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 교차검증 모델 만들기\n",
    "실전에서 모델이 얼마나 잘 작동할지 평가하고 싶습니다.\n",
    "\n",
    "데이터 전처리 파이프라인을 만들고 모델을 훈련한 다음 교차검증으로 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 숫자 데이터셋을 로드합니다.\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = digits.data\n",
    "\n",
    "# 타깃 벡터를 만듭니다.\n",
    "target = digits.target\n",
    "\n",
    "# 표준화 객체를 만듭니다.\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# 로지스틱 회귀 객체를 만듭니다.\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# 표준화한 다음 로지스틱 회귀를 실행하는 파이프라인을 만듭니다.\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# k-폴드 교차검증을 만듭니다.\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# k-폴드 교차검증을 수행합니다.\n",
    "cv_results = cross_val_score(pipeline, # 파이프라인\n",
    "                             features, # 특성행렬\n",
    "                             target, # 타깃 벡터\n",
    "                             cv=kf, # 교차검증 기법\n",
    "                             scoring=\"accuracy\", # 평가 지표\n",
    "                             n_jobs=-1) # 모든 CPU 코어 사용\n",
    "\n",
    "# 평균을 계산합니다.\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-폴드 교차검증(k-fold cross-validation, KFCV)에서는 데이터를 fold라고 부르는 $k$개의 부분으로 나눕니다.$k$-1개 폴드를 하나의 훈련 세트로 합쳐 모델을 훈련하고 남은 폴드를 테스트 세트처럼 사용합니다. 이를 $k$번 반복합니다. 반복마다 다른 폴드를 테스트 세트로 사용합니다. $k$번 반복에서 얻은 모델 성능을 평균하여 최종 성능을 산출합니다.\n",
    "\n",
    "해결에서 10개의 폴드를 사용하여 $k$-폴드 교차검증을 수행했습니다. 평가 정수는 cv_results에 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10개 폴드의 점수를 모두 확인하기\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFCV를 사용할 때 고려해야 할 중요한 점이 세 가지 있습니다. 첫째, KFCV는 각 샘플이 다른 샘플과 독립적으로 생성되었다고 가정합니다(즉 데이터는 independent identically distributed, iid입니다). 데이터가 iid라면 폴드를 나누기 전에 샘플을 섞는 것이 좋은 생각입니다. 사이킷런에서는 shuffle=True로 지정하여 섞을 수 있습니다.\n",
    "\n",
    "둘째, KFCV를 사용하여 classifier를 평가할 때, 각 타깃 클래스의 샘플이 거의 같은 비율로 폴드에 담기는 것이 좋습니다(계층별 $k$-폴드, stratified k-fold라고 부릅니다). 예를 들어 성별 타깃 벡터 중에서 80% 샘플이 남성이라면 각 폴드도 80% 남성과 20% 여성 샘플로 이루어져야 합니다. 사이킷런에서는 KFold 클래스를 StratifiedKFold로 바꾸어 계층별 $k$-폴드 교차검증을 수행할 수 있습니다.\n",
    "\n",
    "마지막으로 검증 세트나 교차검증을 사용할 때 훈련 세트에서 데이터를 전처리하고 이 변환을 훈련 세트와 테스트 세트에 모두 적용하는 것이 중요합니다. 예를 들면 표준화 객체 standardizer의 fit 메서드를 호출하여 훈련 세트의 평균과 분산을 계산합니다. 그다음 이 변환을 (transform 메서드를 사용해) 훈련 세트와 테스트 세트에 모두 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 훈련 세트로 standardizer의 fit 메서드를 호출합니다.\n",
    "standardizer.fit(features_train)\n",
    "\n",
    "# 훈련 세트와 테스트 세트에 모두 적용합니다.\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하는 이유는 테스트 세트를 모르는 척하기 위해서입니다. 이 전처리 객체를 훈련 세트와 테스트 세트에 있는 모든 샘플로 훈련한다면 테스트 세트의 정보가 훈련 세트로 유출된 것입니다. 이 규칙은 특성 선택 같은 모든 전처리 단계에 적용됩니다.\n",
    "\n",
    "사이킷런의 pipeline 패키지는 교차검증 기법을 사용할 때 이 규칙을 손쉽게 구현할 수 있도록 도와줍니다. 먼저 데이터를 전처리 (예를 들면 standardizer)하고 모델(로지스틱 회귀인 logit)을 훈련하는 파이프라인을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인을 만듭니다.\n",
    "pipeline = make_pipeline(standardizer, logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음 이 파이프라인으로 KFCV를 실행하면 사이킷런이 모든 작업을 알아서 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-폴드 교차검증 수행\n",
    "cv_results = cross_val_score(pipeline, # 파이프라인\n",
    "                             features, # 특성행렬\n",
    "                             target, # 타깃 벡터\n",
    "                             cv=kf, # 교차검증 기법\n",
    "                             scoring=\"accuracy\", # 평가 지표\n",
    "                             n_jobs=-1) # 모든 CPU 코어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score에는 아직 이야기하지 않은 중요한 세 개의 매개변수가 있습니다. cv는 교차검증 기법을 결정합니다. $k$-폴드를 가장 많이 사용하지만 다른 방식도 있습니다. LOOCV(leave-one-out-cross-validation)는 폴드의 수 $k$가 샘플의 개수와 같습니다. scoring 매개변수는 이 장의 다른 여러 레시피에서 설명할 모델 성공의 측정 방법을 결정합니다. 마지막으로 n_jobs=-1은 사이킷런에게 가용한 모든 코어를 사용하도록 지시합니다. 예를 들어 사용하는 컴퓨터에 (요즘 노트북의 기본 사양인) 네 개의 코어가 있다면 사이킷런은 네 개의 코어를 모두 동시에 사용해 작업의 속도를 높입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOCV는 LeaveOneOut 클래스에 구현되어 있습니다. LeaveOneOut 클래스는 KFold(n_splits=n)과 동일합니다(n은 샘플 개수).\n",
    "\n",
    "KFold와 StratifiedKFold의 n_splits 매개변수 기본값은 3입니다. 사이킷런 0.22 버전부터 이 값이 5로 바뀝니다.\n",
    "\n",
    "ShuffleSplit는 반복 횟수에 상관없이 훈련 폴드와 테스트 폴드 크기를 임의로 지정할 수 있습니다. train_size, test_size 매개변수에는 사용할 샘플 개수 또는 비율을 입력합니다. 반복마다 랜덤하게 분할하기 때문에 하나의 샘플이 여러 번 테스트 폴드에 포함될 수 있습니다. 계층별 교차검증을 위한 StratifiedShuffleSplit도 있습니다. 다음 코드는 훈련 폴드로 50%, 테스트 폴드로 20%를 사용하여 10번 반복하는 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630555555555554"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# ShuffleSplit 분할기를 만듭니다.\n",
    "ss = ShuffleSplit(n_splits=10, train_size=0.5, test_size=0.2, random_state=42)\n",
    "\n",
    "# 교차검증을 수행합니다.\n",
    "cv_results = cross_val_score(pipeline,\n",
    "                             features,\n",
    "                             target,\n",
    "                             cv=ss,\n",
    "                             scoring=\"accuracy\",\n",
    "                             n_jobs=-1)\n",
    "\n",
    "# 평균을 계산합니다.\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 0.19 버전에서는 교차검증을 반복하여 실행할 수 있는 RepeatedKFold와 StratifiedRepeatedKFold가 추가되었습니다. 다음 코드는 10-폴드 교차검증을 5번 반복하는 RepeatedKFold의 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# RepeatedKFold 분할기를 만듭니다.\n",
    "rfk = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)\n",
    "\n",
    "# 교차검증을 수행합니다.\n",
    "cv_results = cross_val_score(pipeline,\n",
    "                             features,\n",
    "                             target,\n",
    "                             cv=rfk,\n",
    "                             scoring=\"accuracy\",\n",
    "                             n_jobs=-1)\n",
    "\n",
    "# 검증 점수 개수를 확인합니다.\n",
    "len(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 50개의 교차검증 점수가 생성되었습니다. n_splits 매개변수 기본값은 5이고 n_repeats 매개변수 기본값은 10입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 기본 회귀 모델 만들기\n",
    "다른 모델과 비교하기 위해 간단한 기본 회귀 모델을 만들고 싶습니다.\n",
    "\n",
    "사이킷런의 DummyRegressor를 사용하여 기본 모델로 사용할 간단한 dummy 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "boston = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "features = np.hstack([boston.values[::2, :], boston.values[1::2, :2]])\n",
    "target = boston.values[1::2, 2]\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "# boston = load_boston()\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "# features, target = boston.data, boston.target\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 나눕니다.\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "# 더미 회귀 모델을 만듭니다.\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# 더미 회귀 모델을 훈련합니다.\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# R^2 점수를 계산합니다.\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 모델을 훈련하고 평가하여 성능 점수를 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.635463843320215"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 간단한 선형 회귀 모델을 훈련합니다.\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "# R^2 점수를 계산합니다.\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DummyRegressor 클래스는 실제 모델과 비교하기 위해 사용할 수 있는 매우 간단한 모델을 만듭니다. 기존 제품이나 시스템의 단순한 예측 방식을 흉내 내는 데 종종 사용합니다. 예를 들면 모든 새로운 사용자는 특성에 상관없이 첫 달에 100달러를 사용할 것이라고 가정하도록 애초부터 시스템에 하드코딩되어 있을지 모릅니다. 이런 가정을 기본 모델로 삼으면 머신러닝 방식을 사용했을 때 장점을 명확히 확인할 수 있습니다.\n",
    "\n",
    "DummyRegressor 클래스는 strategy 매개변수를 사용하여 예측 방법을 지정합니다. 훈련 세트의 평균 또는 중간값을 사용할 수 있습니다. 또한 strategy를 constant로 지정하고 constant 매개변수를 사용하면 모든 샘플에 대해 일정한 값으로 예측하는 더미 회귀 모델을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06510502029325727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 샘플에 대해 20으로 예측하는 더미 회귀 모델을 만듭니다.\n",
    "clf = DummyRegressor(strategy='constant', constant=20)\n",
    "clf.fit(features_train, target_train)\n",
    "\n",
    "# 점수를 계산합니다.\n",
    "clf.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score 메서드에 대해 언급할 것이 하나 있습니다. 기본적으로 score 메서드는 결정계수($R^2$)값을 반환합니다. $$R^2 = 1-\\frac{\\sum_{i}(y_i -\\hat{y_i})^2}{\\sum_i(y_i-\\bar{y})^2}$$\n",
    "여기에서 $y_i$는 샘플의 정답 타깃값입니다. $\\hat{y_i}$은 예측한 값이고 $\\bar{y}$은 타깃 벡터의 평균값입니다. $R^2$이 1에 가까울수록 특성이 타깃 벡터의 분산을 잘 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strategy가 mean일 때 평균값으로 예측하고 median일 때 중간값으로 예측합니다. strategy='quantile'로 지정하면 quantile 매개변수에 지정한 분위값을 예측으로 사용합니다. quantile 매개변수에는 0과 1 사이의 실숫값을 지정하며 0.5일 때 중간값과 같고 0이면 최솟값, 1이면 최댓값입니다. 다음 코드는 훈련 세트의 타깃값의 최댓값으로 예측을 만드는 DummyRegressor의 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50., 50.,\n",
       "       50., 50., 50., 50., 50., 50., 50., 50., 50., 50.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DummyRegressor(strategy='quantile', quantile=1.0)\n",
    "clf.fit(features_train, target_train)\n",
    "\n",
    "# 훈련 세트 타깃의 최댓값으로 예측합니다.\n",
    "clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 훈련 세트의 타깃에서 최댓값을 확인합니다.\n",
    "np.max(target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 기본 분류 모델 만들기\n",
    "다른 모델과 비교하기 위해 간단한 기본 회귀 모델을 만들고 싶습니다.\n",
    "\n",
    "사이킷런의 DummyClassifier를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 다른 모델과 기본 모델을 비교하여 더 나은지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 분류 모델을 만듭니다.\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# 모델을 훈련합니다.\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "# 정확도 점수를 계산합니다.\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 모델의 성능을 측정하는 일반적인 방법은 랜덤한 추측보다 얼마나 더 나은지 비교하는 것입니다. 사이킷런의 DummyClassifier를 사용하면 이런 비교를 쉽게할 수 있습니다. strategy 매개변수는 예측값을 생성하는 여러 가지 옵션을 제공합니다. 전형적으로 많이 사용하는 두 가지 전략이 있습니다. 첫 번째, stratified 옵션은 훈련 세트에 있는 타깃 벡터의 클래스 비율에 비례하는 예측을 만듭니다(즉 훈련 세트에서 샘플의 20%가 여성이라면 DummyClassifier는 20%를 여성으로 예측합니다). 두 번째, uniform 옵션은 클래스 비중이 균등하도록 랜덤하게 예측합니다. 예를 들어 샘플의 20%가 여성이고 80%가 남성일 때 uniform 옵션은 50%는 여성, 50%는 남성으로 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strategy에서 자주 사용하는 또 다른 옵션은 most_frequent입니다. 이 옵션은 무조건 훈련 세트에서 가장 많은 타깃 레이블로 예측을 만듭니다. 다음 코드는 most_frequent 옵션을 사용하는 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# 훈련 세트 타깃에서 가장 많은 값으로 예측합니다.\n",
    "dummy.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트에 있는 타깃값을 확인해보면 클래스 레이블 2가 가장 많습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 34, 41], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트의 타깃 개수를 확인합니다.\n",
    "np.bincount(target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
